{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# The following has taken the code used to generate results for our real time algorithm and breaks it down into\n",
    "# a collection of functions that can be used or altered to fit Kiana's systems. The first function is the main function\n",
    "# which uses all functions to do the tasks necessary to keep track of device matches in real time given a stream of\n",
    "# data. This stream of live data that Kiana actually uses is not one we had access to during our project. Because of\n",
    "# this, we were forced to simulate this stream using a static array sorted by time. The use of variables base_time,\n",
    "# this_time, and i is explicitly for that purpose and would be changed if this code was ever properly integrated in\n",
    "# Kiana systems. Currently the data stream is represented as the variable \"data_stream\" but is treated as a pandas\n",
    "# dataframe in this code. This data stream is meant to be a stream of each data point collected in a single day.\n",
    "#\n",
    "# Algorithm: Data streams in by row in the form it was given to us for this project. A dictionary has table is\n",
    "# constructed to store the data every \"time_step\" (timedelta variable) number of seconds. As a data point is added,\n",
    "# it is hashed based on its location within a given \"radius\" (int variable) as well as the floor it was recorded on.\n",
    "# this gives us a hash table where every entry that has a list longer than one represents a match for that time step.\n",
    "# A match in this case, means two MacId's were caught within \"radius\" of each other in the given two second interval.\n",
    "# After each time step, the data is then used to update the data structure keeping track of all matched pairs and their\n",
    "# history. The variable name for this task is \"match_tracker\", it is a dictionary where the keys are the MacId's of a\n",
    "# given pair of matched devices, sorted in lexicographic order. We also track the positions and frequency of being\n",
    "# detected of every MacId in the dictionary \"id_tracker\" which uses the MacId strings as keys. The purpose of these\n",
    "# data structures is to be searchable at any time in the case of a stolen person or device, or to be used to update\n",
    "# population statistics based on which devices are being double counted. In using this algorithm you gain access to\n",
    "# information on which MacId's consistently show up together and their individual paths. We have developed metrics as\n",
    "# well to allow us to draw conclusions on which devices we consider to be from the same person.\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_stream):\n",
    "    # these two parameters can be altered if Kiana is able to perform experiments and conclude they should be changed.\n",
    "    time_step = '2 seconds'\n",
    "    radius = 0.0000359  # about 4 meters\n",
    "\n",
    "    # keeps track of each match made throughout the day\n",
    "    match_tracker = dict()\n",
    "\n",
    "    # keeps track of how each Id throughout the day\n",
    "    id_tracker = dict()\n",
    "\n",
    "    # these variables are only used in simulating the data stream\n",
    "    base_time = pd.to_datetime(data_stream['datetime'][0])\n",
    "    this_time = pd.to_datetime(data_stream['datetime'][0])\n",
    "    while data_stream:\n",
    "        current_buffer = dict()\n",
    "\n",
    "        # this variable is only used in simulating the data stream\n",
    "        i = 0\n",
    "\n",
    "        while this_time < base_time + pd.Timedelta(time_step):\n",
    "            cur_id = data_stream['MacId'][i]\n",
    "            lat = data_stream['lat'][i]\n",
    "            lng = data_stream['lng'][i]\n",
    "            floor = data_stream['floor'][i]\n",
    "            time_caught = data_stream['datetime'][i]\n",
    "\n",
    "            add_id_to_grid(current_buffer, cur_id, lat, lng, floor, radius)\n",
    "            update_id_tracker(id_tracker, cur_id, lat, lng, time_caught)\n",
    "\n",
    "            # more data stream simulation\n",
    "            i += 1\n",
    "            this_time = data_stream['datetime'][i]\n",
    "\n",
    "        update_match_tracker(current_buffer, match_tracker, base_time)\n",
    "\n",
    "        # more data stream simulation\n",
    "        base_time = this_time\n",
    "\n",
    "    print_results(match_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Use: this function is meant to take the current time buffer of data and add it to the ongoing data structure that\n",
    "# stores match history.\n",
    "#\n",
    "# input:\n",
    "# buffer - the dictionary containing data on the past time step and what matches were found\n",
    "# tracker - the dictionary being used to keep track of match history\n",
    "# match_base_time - Each time step has a start time and a stop time, This is the start time, and is the time we use to\n",
    "# refer to all data caught in this time step\n",
    "#\n",
    "# output:\n",
    "# There is no explicit output, but by the end of this function the match_tracker should be up to date.\n",
    "# The match_tracker key was explained in the opening statements, the value for each key is a list with three dimensions.\n",
    "# The first dimension is an int representing how many times the match has been made, the second is as list of each\n",
    "# time step base_time each match was made (should be as long as the int in the first dimension), the third dimension\n",
    "# is the matched MacID's themselves\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_match_tracker(buffer, tracker, match_base_time):\n",
    "    # update probabilities with current buffer results\n",
    "    for key in buffer:\n",
    "        # remove duplicates\n",
    "        matched_devices = remove_dup(buffer[key])\n",
    "        # match made if hash table has multiple entries in one spot\n",
    "        if (len(matched_devices) > 1) and (len(matched_devices) < 7):\n",
    "            matched_devices = sorted(matched_devices)  # always hash sorted list to find duplicates\n",
    "            # consider all subsets of size 2\n",
    "            all_subsets = list(itertools.combinations(range(len(matched_devices)), 2))\n",
    "            for subset in all_subsets:\n",
    "                these_devices = [matched_devices[subset[0]], matched_devices[subset[1]]]\n",
    "\n",
    "                match_hash = hash(tuple(these_devices))\n",
    "\n",
    "                # update or initialize this match\n",
    "                if match_hash in tracker:\n",
    "                    tracker[match_hash][0] += 1\n",
    "                    tracker[match_hash][1].append(match_base_time)\n",
    "                else:\n",
    "                    tracker[match_hash] = [1, [match_base_time], these_devices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Use: This function is meant to take in data on a current data point and the current time buffer data and update it\n",
    "# based on the new data point. The update is done by adding the point to the hash dictionary.\n",
    "#\n",
    "# input:\n",
    "# buffer - the has dictionary for the current time buffer\n",
    "# this_id, lat, lng, floor - This is the MacId, latitude, longitude, and floor location data for the current data point\n",
    "# r - the radius being used for the hash\n",
    "#\n",
    "# output: no explicit output, the current buffer should now include data on the passed data point\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_id_to_grid(buffer, this_id, lat, lng, floor, r):\n",
    "\n",
    "    # hash each macid based on location\n",
    "    v1 = math.floor(lng / r)\n",
    "    v2 = math.floor(lat / r)\n",
    "    v3 = floor\n",
    "    key = hash((v1, v2, v3))\n",
    "    if key in buffer:\n",
    "        buffer[key].append(this_id)\n",
    "    else:\n",
    "        buffer[key] = [this_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Use: this function updates the passed id_tracker with information on the passed data point.\n",
    "#\n",
    "# input:\n",
    "# tracker - the ID tracker\n",
    "# this_id, lat, lng - This is the MacId, latitude, longitude data for the current data point\n",
    "# time_ - the time the datapoint was caught\n",
    "#\n",
    "# output: no output, the id_tracker should be updated when this function finishes\n",
    "# id_tracker structure: dictionary who's keys are the MacId's of each device. The values are each lists of length three\n",
    "# The first entry is the number of times this Id was caught, the second is as list of (lat, lng) tuples for each time\n",
    "# the id was caught, the third is a list of times the id was caught at, should be the same length as the second entry.\n",
    "# and the length should be equal to the first entry value.\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_id_tracker(tracker, this_id, lat, lng, time_):\n",
    "    # update mac tracker\n",
    "    if this_id in tracker:\n",
    "        tracker[this_id][0] += 1\n",
    "        tracker[this_id][1].append((lat, lng))\n",
    "        tracker[this_id][2].append(time_)\n",
    "    else:\n",
    "        tracker[this_id] = []\n",
    "        tracker[this_id].append(1)\n",
    "        tracker[this_id].append([(lat, lng)])\n",
    "        tracker[this_id].append(time_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Use: This function computes the time metric based on two passed MacId's\n",
    "#\n",
    "# input:\n",
    "# id1, id2 - the two MacId's as strings you wish to compute the time metric for\n",
    "# id_tracker, match_tracker - the data structures with history's of each matched pair and MacId\n",
    "#\n",
    "# output: score, -1 if score could not be computed\n",
    "# Score = 2 * the amount of time matched/ (time spent in Museum for id1 + time spend in Museum for id2)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_time_metric(id1, id2, id_tracker, match_tracker):\n",
    "    dev1_tot_time = (id_tracker[id1][2][-1].hour - id_tracker[id1][2][0].hour) * 60 + id_tracker[id1][2][-1].minute - \\\n",
    "                    id_tracker[id1][2][0].minute\n",
    "    dev2_tot_time = (id_tracker[id2][2][-1].hour - id_tracker[id2][2][0].hour) * 60 + id_tracker[id2][2][-1].minute - \\\n",
    "                    id_tracker[id2][2][0].minute\n",
    "\n",
    "    devs = sorted([id1, id2])\n",
    "    time_matched = (match_tracker[hash(tuple(devs))][2][-1].hour - match_tracker[hash(tuple(devs))][2][0].hour) * 60 + \\\n",
    "                   match_tracker[hash(tuple(devs))][2][-1].minute - match_tracker[hash(tuple(devs))][2][0].minute\n",
    "    try:\n",
    "        score = (2 * time_matched) / (dev1_tot_time + dev2_tot_time)\n",
    "    except ZeroDivisionError:\n",
    "        score = -1\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Use: This metric computes the match_time_metric and the adjusts it based on how often matches were made\n",
    "#\n",
    "# input:\n",
    "# id1, id2 - the two MacId's as strings you wish to compute the time metric for\n",
    "# id_tracker, match_tracker - the data structures with history's of each matched pair and MacId\n",
    "# output: score, -1 if the score could not be computed\n",
    "#\n",
    "# Score = time_metric_score * c\n",
    "# c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_time_metric(id1, id2, id_tracker, match_tracker):\n",
    "    score = match_time_metric(id1, id2, id_tracker, match_tracker)\n",
    "    devs = sorted([id1, id2])\n",
    "\n",
    "    score = score * match_tracker[hash(tuple(devs))][0] / (id_tracker[id1][0] + id_tracker[id2][0])\n",
    "\n",
    "    if score < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function simply takes a list of strings and returns a list of string without duplicates\n",
    "def remove_dup(duplicate):\n",
    "    final_list = []\n",
    "    for num in duplicate:\n",
    "        if num not in final_list:\n",
    "            final_list.append(num)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is meant to print results as they are seen in the Jupyter notebook for the real time algorithm\n",
    "# it takes the match tracker and id tracker as inputs and does not return anything\n",
    "def print_results(m_tracker):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    counts = []\n",
    "    ids = []\n",
    "    adj_metrics = []\n",
    "    time_metrics = []\n",
    "    for key, match_list in m_tracker.items():\n",
    "        counts.append(match_list[1])\n",
    "        ids.append(match_list[3])\n",
    "\n",
    "        time_metrics.append(match_time_metric(match_list[3][0], match_list[3][1]))\n",
    "        adj_metrics.append(adj_time_metric(match_list[3][0], match_list[3][1]))\n",
    "\n",
    "    df['counts'] = counts\n",
    "    df['time metric'] = time_metrics\n",
    "    df['adj metric'] = adj_metrics\n",
    "    df['MacId'] = ids\n",
    "\n",
    "    df = df.sort_values(by=['counts', 'time metric', 'adj metric'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "    for i in range(5000):\n",
    "        if df.counts[i] > 100:\n",
    "            print(df.MacId[i], 'time metric:', df['time metric'][i], 'adjusted metric:', df['adj metric'][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
